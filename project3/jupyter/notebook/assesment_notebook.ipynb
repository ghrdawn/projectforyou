{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.master(\"local\"). \\\n",
    "    appName(\"pyspark-1\"). \\\n",
    "    getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType\n",
    "\n",
    "schema = StructType([\n",
    "    StructField('Job ID', StringType(), True),\n",
    "    StructField('Agency', StringType(), True),\n",
    "    StructField('Posting Type', StringType(), True),\n",
    "    StructField('# Of Positions', IntegerType(), True),\n",
    "    StructField('Business Title', StringType(), True),\n",
    "    StructField('Civil Service Title', StringType(), True),\n",
    "    StructField('Title Code No', StringType(), True),\n",
    "    StructField('Level', StringType(), True),\n",
    "    StructField('Job Category', StringType(), True),\n",
    "    StructField('Full-Time/Part-Time indicator', StringType(), True),\n",
    "    StructField('Salary Range From', DoubleType(), True),\n",
    "    StructField('Salary Range To', DoubleType(), True),\n",
    "    StructField('Salary Frequency', StringType(), True),\n",
    "    StructField('Work Location', StringType(), True),\n",
    "    StructField('Division/Work Unit', StringType(), True),\n",
    "    StructField('Job Description', StringType(), True),\n",
    "    StructField('Minimum Qual Requirements', StringType(), True),\n",
    "    StructField('Preferred Skills', StringType(), True),\n",
    "    StructField('Additional Information', StringType(), True),\n",
    "    StructField('To Apply', StringType(), True),\n",
    "    StructField('Hours/Shift', StringType(), True),\n",
    "    StructField('Work Location 1', StringType(), True),\n",
    "    StructField('Recruitment Contact', StringType(), True),\n",
    "    StructField('Residency Requirement', StringType(), True),\n",
    "    StructField('Posting Date', StringType(), True),\n",
    "    StructField('Post Until', StringType(), True),\n",
    "    StructField('Posting Updated', StringType(), True),\n",
    "    StructField('Process Date', StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Job ID: string (nullable = true)\n",
      " |-- Agency: string (nullable = true)\n",
      " |-- Posting Type: string (nullable = true)\n",
      " |-- # Of Positions: integer (nullable = true)\n",
      " |-- Business Title: string (nullable = true)\n",
      " |-- Civil Service Title: string (nullable = true)\n",
      " |-- Title Code No: string (nullable = true)\n",
      " |-- Level: string (nullable = true)\n",
      " |-- Job Category: string (nullable = true)\n",
      " |-- Full-Time/Part-Time indicator: string (nullable = true)\n",
      " |-- Salary Range From: double (nullable = true)\n",
      " |-- Salary Range To: double (nullable = true)\n",
      " |-- Salary Frequency: string (nullable = true)\n",
      " |-- Work Location: string (nullable = true)\n",
      " |-- Division/Work Unit: string (nullable = true)\n",
      " |-- Job Description: string (nullable = true)\n",
      " |-- Minimum Qual Requirements: string (nullable = true)\n",
      " |-- Preferred Skills: string (nullable = true)\n",
      " |-- Additional Information: string (nullable = true)\n",
      " |-- To Apply: string (nullable = true)\n",
      " |-- Hours/Shift: string (nullable = true)\n",
      " |-- Work Location 1: string (nullable = true)\n",
      " |-- Recruitment Contact: string (nullable = true)\n",
      " |-- Residency Requirement: string (nullable = true)\n",
      " |-- Posting Date: string (nullable = true)\n",
      " |-- Post Until: string (nullable = true)\n",
      " |-- Posting Updated: string (nullable = true)\n",
      " |-- Process Date: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"/dataset/nyc-jobs.csv\", header=True, schema=schema)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql.functions import col,max,min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_salary_frequency(df: DataFrame) -> list:\n",
    "    row_list = df.select('Salary Frequency').distinct().collect()\n",
    "    return [row['Salary Frequency'] for row in row_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Whats the number of jobs posting per category (Top 10)?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top10_jobs_posting_per_category(df: DataFrame) -> list:\n",
    "    job_posting_per_category = df.groupBy('Job Category').count().orderBy(col('count').desc())\n",
    "    return [(row[0], row[1]) for row in job_posting_per_category.take(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|        Job Category|Job Id|\n",
      "+--------------------+------+\n",
      "|Engineering, Arch...|   504|\n",
      "|Technology, Data ...|   313|\n",
      "|       Legal Affairs|   226|\n",
      "|Public Safety, In...|   182|\n",
      "|Building Operatio...|   181|\n",
      "|Finance, Accounti...|   169|\n",
      "|Administration & ...|   134|\n",
      "|Constituent Servi...|   129|\n",
      "|              Health|   125|\n",
      "|Policy, Research ...|   124|\n",
      "+--------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schema = list = ['Job Category', 'Job Id']\n",
    "result_data = get_top10_jobs_posting_per_category(df)\n",
    "result_df = spark.createDataFrame(data = result_data, schema = schema)\n",
    "result_df.show()\n",
    "result_df.coalesce(1).write.mode('overwrite').format('csv').save('resultset/get_top10_jobs_posting_per_category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Whats the salary distribution per job category?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_salary_distribution_per_job_category(df: DataFrame) -> list:\n",
    "    salary_distribution_per_job_category = df.groupBy(col('Job Category'))\\\n",
    "                                            .agg(min(col('Salary Range From')).alias('Salary Range From')\\\n",
    "                                                 , max(col('Salary Range To')).alias('Salary Range To'))\n",
    "\n",
    "    return [(row[0], row[1], row[2]) for row in salary_distribution_per_job_category.collect()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------------+---------------+\n",
      "|        Job Category|Salary Range From|Salary Range To|\n",
      "+--------------------+-----------------+---------------+\n",
      "|Administration & ...|          90000.0|       100000.0|\n",
      "|Health Policy, Re...|          82008.0|       180000.0|\n",
      "|Administration & ...|          54100.0|        83981.0|\n",
      "|Information Techn...|          68239.0|        85644.0|\n",
      "|Finance, Accounti...|          55659.0|        70390.0|\n",
      "|Engineering, Arch...|           539.12|       118610.0|\n",
      "|Legal Affairs Pol...|          54165.0|       168433.0|\n",
      "|Administration & ...|          45491.0|        60660.0|\n",
      "|Constituent Servi...|             15.5|       156829.0|\n",
      "|Building Operatio...|             15.5|       234402.0|\n",
      "|Engineering, Arch...|          69940.0|       186555.0|\n",
      "|Constituent Servi...|          52524.0|        81535.0|\n",
      "|Administration & ...|          65731.0|        75591.0|\n",
      "|       Legal Affairs|          19.9179|       208826.0|\n",
      "|Engineering, Arch...|             15.5|           19.9|\n",
      "|Finance, Accounti...|          38851.0|       133040.0|\n",
      "|Constituent Servi...|             15.5|           15.5|\n",
      "|Administration & ...|             15.5|           19.9|\n",
      "|Health Legal Affairs|          61237.0|        81801.0|\n",
      "|Administration & ...|          27.9267|        58987.0|\n",
      "+--------------------+-----------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schema = StructType([\n",
    "    StructField('Job Category', StringType(), True),\n",
    "    StructField('Salary Range From', DoubleType(), True),\n",
    "    StructField('Salary Range To', DoubleType(), True),\n",
    "])\n",
    "result_data = get_salary_distribution_per_job_category(df)\n",
    "result_df = spark.createDataFrame(data = result_data, schema = schema)\n",
    "result_df.show()\n",
    "result_df.coalesce(1).write.mode('overwrite').format('csv').save('resultset/get_salary_distribution_per_job_category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Is there any correlation between the higher degree and the salary?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when,instr\n",
    "df_target = df.withColumn('Degree Level', when(instr(col('Minimum Qual Requirements'), 'master''s degree') > 0, 2)\\\n",
    "                                        .when(instr(col('Minimum Qual Requirements'), 'baccalaureate degree') > 0, 1)\\\n",
    "                                         .otherwise(0))\n",
    "\n",
    "#df_target.select('Minimum Qual Requirements', 'Degree Level').show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16851524924303374"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_target.corr('Degree Level', 'Salary Range To')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21567669052524574"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_target.corr('Degree Level', 'Salary Range From')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above exercise shows positive correlation between higher degree and the salary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of test function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "mock_data = [('A', 'Annual'), ('B', 'Daily')]\n",
    "expected_result = ['Annual', 'Daily']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_get_salary_frequency(mock_data: list, \n",
    "                              expected_result: list,\n",
    "                              schema: list = ['id', 'Salary Frequency']):  \n",
    "    mock_df = spark.createDataFrame(data = mock_data, schema = schema)\n",
    "    assert get_salary_frequency(mock_df) == expected_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test : get_top10_jobs_posting_per_category**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_get_top10_jobs_posting_per_category(mock_data: list, \n",
    "                              expected_result: list,\n",
    "                              schema: list = ['Job Category', 'Job Id']):\n",
    "    mock_df = spark.createDataFrame(data = mock_data, schema = schema)\n",
    "    assert sorted(get_top10_jobs_posting_per_category(mock_df)) == sorted(expected_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "mock_data = [('C1', 1), ('C1', 2), ('C1', 3),\n",
    "            ('C2', 4), ('C2', 5),\n",
    "            ('C3', 6), ('C3', 7), ('C3', 8),\n",
    "            ('C4', 9), ('C4', 10), ('C4', 11),\n",
    "            ('C5', 12), ('C5', 13), ('C5', 14),('C5', 15),\n",
    "            ('C6', 16), ('C6', 17), ('C6', 18),\n",
    "            ('C7', 19), ('C7', 20),\n",
    "            ('C8', 21), ('C8', 22), ('C8', 23),\n",
    "            ('C9', 24), ('C9', 25), ('C9', 26),('C9', 27), ('C9', 28),\n",
    "            ('C10', 29), ('C10', 30), ('C10', 31),\n",
    "            ('C11', 32)]\n",
    "expected_result = [('C9', 5),\n",
    "                  ('C5', 4),\n",
    "                  ('C6', 3),\n",
    "                  ('C4', 3),\n",
    "                  ('C10', 3),\n",
    "                  ('C3', 3),\n",
    "                  ('C8', 3),\n",
    "                  ('C1', 3),\n",
    "                  ('C7', 2),\n",
    "                  ('C2', 2)]\n",
    "\n",
    "schema = list = ['Job Category', 'Job Id']\n",
    "test_get_top10_jobs_posting_per_category(mock_data, expected_result, schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test: get_salary_distribution_per_job_category**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_get_salary_distribution_per_job_category(mock_data: list, \n",
    "                              expected_result: list,\n",
    "                              schema: StructType([StructField('Job Category', StringType(), True),StructField('Salary Range From', DoubleType(), True),\n",
    "    StructField('Salary Range To', DoubleType(), True),\n",
    "])):\n",
    "    mock_df = spark.createDataFrame(data = mock_data, schema = schema)\n",
    "    assert sorted(get_salary_distribution_per_job_category(mock_df)) == sorted(expected_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "mock_data = [('C1', 10.00, 20.00), ('C1', 15.00, 30.00), ('C1', 30.00, 40.00),\n",
    "            ('C2', 52.50, 60.00), ('C2', 63.00, 70.00), ('C2', 22.14, 30.00), ('C2', 21.14, 75.50),\n",
    "            ('C3', 900.00, 950.00), ('C3', 700.00, 760.00), ('C3', 810.00, 900.00)]\n",
    "expected_result = [('C1', 10.00, 40.00),\n",
    "                  ('C2', 21.14, 75.50),\n",
    "                  ('C3', 700.00, 950.00)]\n",
    "\n",
    "schema = StructType([\n",
    "    StructField('Job Category', StringType(), True),\n",
    "    StructField('Salary Range From', DoubleType(), True),\n",
    "    StructField('Salary Range To', DoubleType(), True),\n",
    "])\n",
    "test_get_salary_distribution_per_job_category(mock_data, expected_result, schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
